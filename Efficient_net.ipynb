{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":332046,"sourceType":"datasetVersion","datasetId":141236}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\n\n\nphysical_devices = tf.config.list_physical_devices(\"GPU\")\n\nif physical_devices:\n    tf.config.experimental.set_memory_growth(physical_devices[0], True)\nelse:\n    print(\"No GPU devices found.\")\nphysical_devices = tf.config.list_physical_devices(\"GPU\")\n\nimport random, numpy as np, os\n#import tensorflow_datasets as tfds\n#tfds.disable_progress_bar()\n#tf.config.experimental.set_memory_growth(physical_devices[0], True)\n#tf.config.run_functions_eagerly(True)\ndef config_gpu(mp=False):\n    print('Eager Model : ', tf.executing_eagerly())\n    print('TensorFlow Cuda Built Test : ', tf.test.is_built_with_cuda)\n    print('TensorFlow GPU Detected : ', tf.test.gpu_device_name())\n    print('TensorFlow System Cuda Version : ', tf.sysconfig.get_build_info()[\"cuda_version\"])\n    print('TensorFlow System CudNN Version : ', tf.sysconfig.get_build_info()[\"cudnn_version\"] )\n\n    AUTO = tf.data.AUTOTUNE\n    GPUS = tf.config.list_physical_devices('GPU')\n    if GPUS:\n        try:\n            for GPU in GPUS:\n                tf.config.experimental.set_memory_growth(GPU, True)\n                logical_gpus = tf.config.list_logical_devices('GPU')\n                print(len(GPUS), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\") \n        except RuntimeError as  RE:\n            print(RE)\n    if mp:\n        tf.keras.mixed_precision.set_global_policy('mixed_float16')\n        print('Mixed precision enabled')\n        \n#tf.keras.utils.set_random_seed(100)\nconfig_gpu(mp=False)\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-14T15:34:03.021950Z","iopub.execute_input":"2024-01-14T15:34:03.022284Z","iopub.status.idle":"2024-01-14T15:34:16.221517Z","shell.execute_reply.started":"2024-01-14T15:34:03.022257Z","shell.execute_reply":"2024-01-14T15:34:16.220520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport tensorflow as tf\nimport cv2\nfrom keras import backend as K\nfrom keras.layers import Layer,InputSpec\nimport keras.layers as kl\nfrom glob import glob\nfrom sklearn.metrics import roc_curve, auc\nfrom keras.preprocessing import image\nfrom tensorflow.keras.models import Sequential\nfrom sklearn.metrics import roc_auc_score\nfrom tensorflow.keras import callbacks \nfrom tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\nfrom  matplotlib import pyplot as plt\nfrom tensorflow.keras import Model\nfrom keras.layers import Lambda\nfrom tensorflow.keras.layers import concatenate,Dense, Conv2D, MaxPooling2D, Flatten,Input,Activation,add,AveragePooling2D,BatchNormalization,Dropout\n%matplotlib inline\nimport shutil\nfrom sklearn.metrics import  precision_score, recall_score, accuracy_score,classification_report ,confusion_matrix\nfrom tensorflow.python.platform import build_info as tf_build_info\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\n\nfrom PIL import ImageFile","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:35:28.932701Z","iopub.execute_input":"2024-01-14T15:35:28.933456Z","iopub.status.idle":"2024-01-14T15:35:28.945689Z","shell.execute_reply.started":"2024-01-14T15:35:28.933423Z","shell.execute_reply":"2024-01-14T15:35:28.944516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os, cv2\nimport random, math\nimport numpy as np \nimport pandas as pd\nfrom PIL import Image\nimport matplotlib\nmatplotlib.use(\"Agg\")\nimport matplotlib.pyplot as plt\n\nimport tensorflow, keras\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom keras.preprocessing.image import img_to_array, load_img\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.optimizers import SGD, Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import backend as K\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:35:35.469511Z","iopub.execute_input":"2024-01-14T15:35:35.470180Z","iopub.status.idle":"2024-01-14T15:35:35.477723Z","shell.execute_reply.started":"2024-01-14T15:35:35.470147Z","shell.execute_reply":"2024-01-14T15:35:35.476630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = '/kaggle/input/basedir/base_dir/train_dir'\ntest_path = '/kaggle/input/basedir/base_dir/val_dir'\nbatch_size = 16\n\ntrain_batch_size = 4\nval_batch_size = 4\nimage_size = 224\n","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:35:39.002083Z","iopub.execute_input":"2024-01-14T15:35:39.002941Z","iopub.status.idle":"2024-01-14T15:35:39.007535Z","shell.execute_reply.started":"2024-01-14T15:35:39.002910Z","shell.execute_reply":"2024-01-14T15:35:39.006538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def custom_augmentation(np_tensor):\n\n  def random_contrast(np_tensor):\n    return np.array(tf.image.random_contrast(np_tensor, 0.5, 2))\n\n  def random_saturation(np_tensor):\n    return np.array(tf.image.random_saturation(np_tensor, 0.2, 3))\n\n  def random_crop(np_tensor):\n    #cropped height between 70% to 130% of an original height\n    new_height = int(np.random.uniform(0.7, 1.30) * np_tensor.shape[0])\n    #cropped width between 70% to 130% of an original width\n    new_width = int(np.random.uniform(0.7, 1.30) * np_tensor.shape[1])\n    # resize to new height and width\n    cropped = tf.image.resize_with_crop_or_pad(np_tensor, new_height, new_width)\n    return np.array(tf.image.resize(cropped, np_tensor.shape[:2]))\n\n  def gaussian_noise(np_tensor):\n    mean = 0\n    # variance: randomly between 1 to 25\n    var = np.random.randint(1, 26)\n    # sigma is square root of the variance value\n    noise = np.random.normal(mean,var**0.5,np_tensor.shape)\n    return np.clip(np_tensor + noise, 0, 255).astype('int')\n\n  def cutout(np_tensor):\n    cutout_height = int(np.random.uniform(0.1, 0.2) * np_tensor.shape[0])\n    cutout_width = int(np.random.uniform(0.1, 0.2) * np_tensor.shape[1])\n    cutout_height_point = np.random.randint(np_tensor.shape[0]-cutout_height)\n    cutout_width_point = np.random.randint(np_tensor.shape[1]-cutout_width)\n    np_tensor[cutout_height_point:cutout_height_point+cutout_height, cutout_width_point:cutout_width_point+cutout_width, :] = 127\n    return np_tensor\n\n  if (np.random.uniform() < 0.1):\n    np_tensor = random_contrast(np_tensor)\n  if (np.random.uniform() < 0.1):\n    np_tensor = random_saturation(np_tensor)\n  if (np.random.uniform() < 0.2):\n    np_tensor = random_crop(np_tensor)\n  if (np.random.uniform() < 0.2):\n    np_tensor = gaussian_noise(np_tensor)\n  if (np.random.uniform() < 0.3):\n    np_tensor = cutout(np_tensor)\n  return np.array(np_tensor)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:35:42.001233Z","iopub.execute_input":"2024-01-14T15:35:42.001932Z","iopub.status.idle":"2024-01-14T15:35:42.016807Z","shell.execute_reply.started":"2024-01-14T15:35:42.001899Z","shell.execute_reply":"2024-01-14T15:35:42.015396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndatagen = ImageDataGenerator(#preprocessing_function=custom_augmentation,\n                            rescale=1./255,\n                             preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n                            horizontal_flip = True,\n                            vertical_flip=True\n)\ndatagen1 = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n                             rescale=1./255,)\n                             #horizontal_flip = True,\n                             #vertical_flip=True,)\n\n\ntrain_batches = datagen.flow_from_directory(train_path,\n                                            target_size=(image_size,image_size),\n                                            batch_size=train_batch_size,)\n                                           #subset='training')\n\nvalid_batches = datagen.flow_from_directory(test_path,\n                                            target_size=(image_size,image_size),\n                                            batch_size=val_batch_size,)\n\ntest_batches = datagen1.flow_from_directory(test_path,\n                                            target_size=(image_size,image_size),\n                                            batch_size=32,\n                                            shuffle=False,)\n                                          #subset='validation')","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:35:45.424949Z","iopub.execute_input":"2024-01-14T15:35:45.425916Z","iopub.status.idle":"2024-01-14T15:35:56.960984Z","shell.execute_reply.started":"2024-01-14T15:35:45.425880Z","shell.execute_reply":"2024-01-14T15:35:56.960207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#densneet\n%matplotlib inline\nimage, label = next(train_batches)\nplt.figure(figsize=(20,10))\ninline = 4\nfor i in range(inline):\n    #print(image.size())\n    plt.subplot(2, inline, i%inline +1)\n    plt.axis('off')\n    plt.imshow(image[i])\n    #plt.title(f'Label: {label}')\n    plt.subplot(2, inline, i%inline +5)\n    plt.axis('off')\n    plt.imshow(image[i].astype(np.uint8))","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:36:03.645476Z","iopub.execute_input":"2024-01-14T15:36:03.645849Z","iopub.status.idle":"2024-01-14T15:36:04.865403Z","shell.execute_reply.started":"2024-01-14T15:36:03.645819Z","shell.execute_reply":"2024-01-14T15:36:04.864344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg = dict(\n           batch_size=4,\n           img_size=384,\n    \n           lr_start=0.000008,\n           lr_max=0.0000325,\n           lr_min=0.000001,\n           lr_rampup=5,\n           lr_sustain=0,\n           lr_decay=0.6,\n           epochs=12,\n    \n           transform_prob=1.0,\n           rot=180.0,\n           shr=2.0,\n           hzoom=8.0,\n           wzoom=8.0,\n           hshift=8.0,\n           wshift=8.0,\n    \n           optimizer='sgd',\n           label_smooth_fac=0.05,\n           tta_steps=20\n            \n        )","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:36:11.058011Z","iopub.execute_input":"2024-01-14T15:36:11.058750Z","iopub.status.idle":"2024-01-14T15:36:11.064677Z","shell.execute_reply.started":"2024-01-14T15:36:11.058716Z","shell.execute_reply":"2024-01-14T15:36:11.063448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install -q efficientnet","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:36:16.875410Z","iopub.execute_input":"2024-01-14T15:36:16.876126Z","iopub.status.idle":"2024-01-14T15:36:30.620651Z","shell.execute_reply.started":"2024-01-14T15:36:16.876087Z","shell.execute_reply":"2024-01-14T15:36:30.619373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import efficientnet.tfkeras as efn","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:38:40.088298Z","iopub.execute_input":"2024-01-14T15:38:40.089023Z","iopub.status.idle":"2024-01-14T15:38:40.093205Z","shell.execute_reply.started":"2024-01-14T15:38:40.088988Z","shell.execute_reply":"2024-01-14T15:38:40.092178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    \n    ''' This function gets the layers inclunding efficientnet ones. '''\n    \n    model_input = tf.keras.Input(shape=(224,224, 3),\n                                 name='img_input')\n\n    dummy = tf.keras.layers.Lambda(lambda x: x)(model_input)\n\n\n\n    x = efn.EfficientNetB3(include_top=False,\n                           weights='noisy-student',\n                           input_shape=(224,224, 3),\n                           pooling='avg')(dummy)\n    x = tf.keras.layers.Dense(7, activation='softmax')(x)\n    \n    \"\"\"\n    x = efn.EfficientNetB4(include_top=False,\n                           weights='noisy-student',\n                           input_shape=(224,224, 3),\n                           pooling='avg')(dummy)\n    x = tf.keras.layers.Dense(7, activation='softmax')(x)\n    outputs.append(x)\n    \"\"\"\n    \"\"\"\n    x = efn.EfficientNetB5(include_top=False,\n                           weights='noisy-student',\n                           input_shape=(224,224, 3),\n                           pooling='avg')(dummy)\n    x = tf.keras.layers.Dense(7, activation='softmax')(x)\n    outputs.append(x)\n    \"\"\"\n\n    model = tf.keras.Model(model_input, x, name='aNetwork')\n    model.summary()\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:40:21.440858Z","iopub.execute_input":"2024-01-14T15:40:21.441226Z","iopub.status.idle":"2024-01-14T15:40:21.448773Z","shell.execute_reply.started":"2024-01-14T15:40:21.441196Z","shell.execute_reply":"2024-01-14T15:40:21.447670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\n# For example, this is how you define a mirrored strategy for synchronous training on multiple GPUs\nstrategy = tf.distribute.MirroredStrategy()","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:40:26.507080Z","iopub.execute_input":"2024-01-14T15:40:26.507440Z","iopub.status.idle":"2024-01-14T15:40:26.882395Z","shell.execute_reply.started":"2024-01-14T15:40:26.507410Z","shell.execute_reply":"2024-01-14T15:40:26.881284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    base = efn.EfficientNetB3(include_top=False,\n                               weights='noisy-student',\n                               input_shape=(224,224, 3),\n                               pooling='avg', classes=7)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:40:28.812356Z","iopub.execute_input":"2024-01-14T15:40:28.812761Z","iopub.status.idle":"2024-01-14T15:40:34.347426Z","shell.execute_reply.started":"2024-01-14T15:40:28.812716Z","shell.execute_reply":"2024-01-14T15:40:34.346494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    efficient = get_model()","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:40:38.457862Z","iopub.execute_input":"2024-01-14T15:40:38.458238Z","iopub.status.idle":"2024-01-14T15:40:45.579251Z","shell.execute_reply.started":"2024-01-14T15:40:38.458202Z","shell.execute_reply":"2024-01-14T15:40:45.578376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compileNewModel():\n    \n    ''' Configuring the model with losses and metrics. '''    \n    \n    with strategy.scope():\n        model = efficient\n\n    with strategy.scope():\n        model.compile(optimizer='sgd', loss='categorical_crossentropy', \n                      metrics=['accuracy'])\n        #tf.keras.metrics.AUC(name='auc')\n    return model\n\ndef getLearnRateCallback(cfg):\n    \n    ''' Using callbacks for learning rate adjustments. '''\n    \n    lr_start = cfg['lr_start']\n    lr_max = cfg['lr_max'] * strategy.num_replicas_in_sync * cfg['batch_size']\n    lr_min = cfg['lr_min']\n    lr_rampup = cfg['lr_rampup']\n    lr_sustain = cfg['lr_sustain']\n    lr_decay = cfg['lr_decay']\n\n    def lrfn(epoch):\n        if epoch < lr_rampup:\n            lr = (lr_max - lr_start) / lr_rampup * epoch + lr_start\n        elif epoch < lr_rampup + lr_sustain:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_rampup -\n                                                lr_sustain) + lr_min\n        return lr\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n    return lr_callback\n\n\ndef learnModel(model, ds_train, cfg, ds_val):\n    \n    ''' Fitting things together for training '''\n    \n    filepath1 = \"Efficient_att_ens.h5\"\n    checkpoint = ModelCheckpoint(filepath1, monitor='val_accuracy', verbose=1, \n                             save_best_only=True, mode='max', save_weights_only = True)\n    callbacks = [getLearnRateCallback(cfg), checkpoint]\n\n    history = model.fit(ds_train,\n                        validation_data=ds_val,\n                        verbose=True,\n                        epochs=200,\n                        callbacks=callbacks)\n\n    return history","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:41:22.659640Z","iopub.execute_input":"2024-01-14T15:41:22.660325Z","iopub.status.idle":"2024-01-14T15:41:22.670677Z","shell.execute_reply.started":"2024-01-14T15:41:22.660281Z","shell.execute_reply":"2024-01-14T15:41:22.669632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#efficient net bou7dou i have to save it tooo.. # hada wavelet with global dolg i have to save it (la 2eme fois je dois uploader les meilleurs poids avant enregistremnt)\nmodel1 = compileNewModel()\nhistory1 = learnModel(model1, train_batches, cfg, valid_batches)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T15:41:27.908392Z","iopub.execute_input":"2024-01-14T15:41:27.909067Z","iopub.status.idle":"2024-01-14T15:53:11.028424Z","shell.execute_reply.started":"2024-01-14T15:41:27.909014Z","shell.execute_reply":"2024-01-14T15:53:11.026773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1.load_weights('Efficient_att_ens.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1.load_weights('Efficient_att_ens.h5')","metadata":{},"execution_count":null,"outputs":[]}]}