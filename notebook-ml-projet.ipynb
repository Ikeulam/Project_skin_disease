{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":332046,"sourceType":"datasetVersion","datasetId":141236}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\n\n\nphysical_devices = tf.config.list_physical_devices(\"GPU\")\n\nif physical_devices:\n    tf.config.experimental.set_memory_growth(physical_devices[0], True)\nelse:\n    print(\"No GPU devices found.\")\nphysical_devices = tf.config.list_physical_devices(\"GPU\")\n\nimport random, numpy as np, os\n#import tensorflow_datasets as tfds\n#tfds.disable_progress_bar()\n#tf.config.experimental.set_memory_growth(physical_devices[0], True)\n#tf.config.run_functions_eagerly(True)\ndef config_gpu(mp=False):\n    print('Eager Model : ', tf.executing_eagerly())\n    print('TensorFlow Cuda Built Test : ', tf.test.is_built_with_cuda)\n    print('TensorFlow GPU Detected : ', tf.test.gpu_device_name())\n    print('TensorFlow System Cuda Version : ', tf.sysconfig.get_build_info()[\"cuda_version\"])\n    print('TensorFlow System CudNN Version : ', tf.sysconfig.get_build_info()[\"cudnn_version\"] )\n\n    AUTO = tf.data.AUTOTUNE\n    GPUS = tf.config.list_physical_devices('GPU')\n    if GPUS:\n        try:\n            for GPU in GPUS:\n                tf.config.experimental.set_memory_growth(GPU, True)\n                logical_gpus = tf.config.list_logical_devices('GPU')\n                print(len(GPUS), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\") \n        except RuntimeError as  RE:\n            print(RE)\n    if mp:\n        tf.keras.mixed_precision.set_global_policy('mixed_float16')\n        print('Mixed precision enabled')\n        \n#tf.keras.utils.set_random_seed(100)\nconfig_gpu(mp=False)\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-10T09:27:05.458261Z","iopub.execute_input":"2024-01-10T09:27:05.466588Z","iopub.status.idle":"2024-01-10T09:27:05.650277Z","shell.execute_reply.started":"2024-01-10T09:27:05.466533Z","shell.execute_reply":"2024-01-10T09:27:05.600966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport tensorflow as tf\nimport cv2\nfrom keras import backend as K\nfrom keras.layers import Layer,InputSpec\nimport keras.layers as kl\nfrom glob import glob\nfrom sklearn.metrics import roc_curve, auc\nfrom keras.preprocessing import image\nfrom tensorflow.keras.models import Sequential\nfrom sklearn.metrics import roc_auc_score\nfrom tensorflow.keras import callbacks \nfrom tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\nfrom  matplotlib import pyplot as plt\nfrom tensorflow.keras import Model\nfrom keras.layers import Lambda\nfrom tensorflow.keras.layers import concatenate,Dense, Conv2D, MaxPooling2D, Flatten,Input,Activation,add,AveragePooling2D,BatchNormalization,Dropout\n%matplotlib inline\nimport shutil\nfrom sklearn.metrics import  precision_score, recall_score, accuracy_score,classification_report ,confusion_matrix\nfrom tensorflow.python.platform import build_info as tf_build_info\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\n\nfrom PIL import ImageFile","metadata":{"execution":{"iopub.status.busy":"2024-01-10T09:27:05.734061Z","iopub.execute_input":"2024-01-10T09:27:05.764077Z","iopub.status.idle":"2024-01-10T09:27:06.157326Z","shell.execute_reply.started":"2024-01-10T09:27:05.764026Z","shell.execute_reply":"2024-01-10T09:27:05.893767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os, cv2\nimport random, math\nimport numpy as np \nimport pandas as pd\nfrom PIL import Image\nimport matplotlib\nmatplotlib.use(\"Agg\")\nimport matplotlib.pyplot as plt\n\nimport tensorflow, keras\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom keras.preprocessing.image import img_to_array, load_img\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.optimizers import SGD, Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import backend as K\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-01-10T09:27:06.227591Z","iopub.execute_input":"2024-01-10T09:27:06.227971Z","iopub.status.idle":"2024-01-10T09:27:06.384988Z","shell.execute_reply.started":"2024-01-10T09:27:06.227943Z","shell.execute_reply":"2024-01-10T09:27:06.352503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = '/kaggle/input/basedir/base_dir/train_dir'\ntest_path = '/kaggle/input/basedir/base_dir/val_dir'\nbatch_size = 16\n\ntrain_batch_size = 4\nval_batch_size = 4\nimage_size = 224\n","metadata":{"execution":{"iopub.status.busy":"2024-01-10T09:27:06.449789Z","iopub.execute_input":"2024-01-10T09:27:06.450546Z","iopub.status.idle":"2024-01-10T09:27:06.689406Z","shell.execute_reply.started":"2024-01-10T09:27:06.450504Z","shell.execute_reply":"2024-01-10T09:27:06.584131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def custom_augmentation(np_tensor):\n\n  def random_contrast(np_tensor):\n    return np.array(tf.image.random_contrast(np_tensor, 0.5, 2))\n\n  def random_saturation(np_tensor):\n    return np.array(tf.image.random_saturation(np_tensor, 0.2, 3))\n\n  def random_crop(np_tensor):\n    #cropped height between 70% to 130% of an original height\n    new_height = int(np.random.uniform(0.7, 1.30) * np_tensor.shape[0])\n    #cropped width between 70% to 130% of an original width\n    new_width = int(np.random.uniform(0.7, 1.30) * np_tensor.shape[1])\n    # resize to new height and width\n    cropped = tf.image.resize_with_crop_or_pad(np_tensor, new_height, new_width)\n    return np.array(tf.image.resize(cropped, np_tensor.shape[:2]))\n\n  def gaussian_noise(np_tensor):\n    mean = 0\n    # variance: randomly between 1 to 25\n    var = np.random.randint(1, 26)\n    # sigma is square root of the variance value\n    noise = np.random.normal(mean,var**0.5,np_tensor.shape)\n    return np.clip(np_tensor + noise, 0, 255).astype('int')\n\n  def cutout(np_tensor):\n    cutout_height = int(np.random.uniform(0.1, 0.2) * np_tensor.shape[0])\n    cutout_width = int(np.random.uniform(0.1, 0.2) * np_tensor.shape[1])\n    cutout_height_point = np.random.randint(np_tensor.shape[0]-cutout_height)\n    cutout_width_point = np.random.randint(np_tensor.shape[1]-cutout_width)\n    np_tensor[cutout_height_point:cutout_height_point+cutout_height, cutout_width_point:cutout_width_point+cutout_width, :] = 127\n    return np_tensor\n\n  if (np.random.uniform() < 0.1):\n    np_tensor = random_contrast(np_tensor)\n  if (np.random.uniform() < 0.1):\n    np_tensor = random_saturation(np_tensor)\n  if (np.random.uniform() < 0.2):\n    np_tensor = random_crop(np_tensor)\n  if (np.random.uniform() < 0.2):\n    np_tensor = gaussian_noise(np_tensor)\n  if (np.random.uniform() < 0.3):\n    np_tensor = cutout(np_tensor)\n  return np.array(np_tensor)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T09:27:06.809863Z","iopub.execute_input":"2024-01-10T09:27:06.838631Z","iopub.status.idle":"2024-01-10T09:27:07.100613Z","shell.execute_reply.started":"2024-01-10T09:27:06.838579Z","shell.execute_reply":"2024-01-10T09:27:07.017999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndatagen = ImageDataGenerator(#preprocessing_function=custom_augmentation,\n                            rescale=1./255,\n                             preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n                            horizontal_flip = True,\n                            vertical_flip=True\n)\ndatagen1 = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n                             rescale=1./255,)\n                             #horizontal_flip = True,\n                             #vertical_flip=True,)\n\n\ntrain_batches = datagen.flow_from_directory(train_path,\n                                            target_size=(image_size,image_size),\n                                            batch_size=train_batch_size,)\n                                           #subset='training')\n\nvalid_batches = datagen.flow_from_directory(test_path,\n                                            target_size=(image_size,image_size),\n                                            batch_size=val_batch_size,)\n\ntest_batches = datagen1.flow_from_directory(test_path,\n                                            target_size=(image_size,image_size),\n                                            batch_size=32,\n                                            shuffle=False,)\n                                          #subset='validation')","metadata":{"execution":{"iopub.status.busy":"2024-01-10T09:27:07.146757Z","iopub.execute_input":"2024-01-10T09:27:07.147187Z","iopub.status.idle":"2024-01-10T09:27:20.609961Z","shell.execute_reply.started":"2024-01-10T09:27:07.147150Z","shell.execute_reply":"2024-01-10T09:27:20.608968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#densneet\n%matplotlib inline\nimage, label = next(train_batches)\nplt.figure(figsize=(20,10))\ninline = 4\nfor i in range(inline):\n    #print(image.size())\n    plt.subplot(2, inline, i%inline +1)\n    plt.axis('off')\n    plt.imshow(image[i])\n    #plt.title(f'Label: {label}')\n    plt.subplot(2, inline, i%inline +5)\n    plt.axis('off')\n    plt.imshow(image[i].astype(np.uint8))","metadata":{"execution":{"iopub.status.busy":"2024-01-10T09:27:20.611204Z","iopub.execute_input":"2024-01-10T09:27:20.611594Z","iopub.status.idle":"2024-01-10T09:27:21.695096Z","shell.execute_reply.started":"2024-01-10T09:27:20.611564Z","shell.execute_reply":"2024-01-10T09:27:21.694069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting TPU as main device for training, if you get warnings while working with tpu's ignore them.\n\nDEVICE = 'TPU'\nif DEVICE == 'TPU':\n    print('connecting to TPU...')\n    try:        \n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        print('Could not connect to TPU')\n        tpu = None\n\n    if tpu:\n        try:\n            print('Initializing  TPU...')\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n            print('TPU initialized')\n        except _:\n            print('Failed to initialize TPU!')\n    else:\n        DEVICE = 'GPU'\n\nif DEVICE != 'TPU':\n    print('Using default strategy for CPU and single GPU')\n    strategy = tf.distribute.get_strategy()\n\nif DEVICE == 'GPU':\n    print('Num GPUs Available: ',\n          len(tf.config.experimental.list_physical_devices('GPU')))\n\nprint('REPLICAS: ', strategy.num_replicas_in_sync)\nAUTO = tf.data.experimental.AUTOTUNE","metadata":{"execution":{"iopub.status.busy":"2024-01-10T09:27:21.696441Z","iopub.execute_input":"2024-01-10T09:27:21.696806Z","iopub.status.idle":"2024-01-10T09:27:21.714127Z","shell.execute_reply.started":"2024-01-10T09:27:21.696770Z","shell.execute_reply":"2024-01-10T09:27:21.713072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Optimizer SGD + Configuration**\n\n","metadata":{}},{"cell_type":"code","source":"cfg = dict(\n           batch_size=4,\n           img_size=384,\n    \n           lr_start=0.000008,\n           lr_max=0.0000325,\n           lr_min=0.000001,\n           lr_rampup=5,\n           lr_sustain=0,\n           lr_decay=0.6,\n           epochs=12,\n    \n           transform_prob=1.0,\n           rot=180.0,\n           shr=2.0,\n           hzoom=8.0,\n           wzoom=8.0,\n           hshift=8.0,\n           wshift=8.0,\n    \n           optimizer='sgd',\n           label_smooth_fac=0.05,\n           tta_steps=20\n            \n        )","metadata":{"execution":{"iopub.status.busy":"2024-01-10T09:27:21.715522Z","iopub.execute_input":"2024-01-10T09:27:21.715845Z","iopub.status.idle":"2024-01-10T09:27:21.728112Z","shell.execute_reply.started":"2024-01-10T09:27:21.715818Z","shell.execute_reply":"2024-01-10T09:27:21.727271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model Wavelet Residual Block**","metadata":{}},{"cell_type":"code","source":"# batch operation usng tensor slice\ndef WaveletTransformAxisY(batch_img):\n    odd_img  = batch_img[:,0::2]\n    even_img = batch_img[:,1::2]\n    L = (odd_img + even_img) / 2.0\n    H = K.abs(odd_img - even_img)\n    return L, H\n\ndef WaveletTransformAxisX(batch_img):\n    # transpose + fliplr\n    tmp_batch = K.permute_dimensions(batch_img, [0, 2, 1])[:,:,::-1]\n    _dst_L, _dst_H = WaveletTransformAxisY(tmp_batch)\n    # transpose + flipud\n    dst_L = K.permute_dimensions(_dst_L, [0, 2, 1])[:,::-1,...]\n    dst_H = K.permute_dimensions(_dst_H, [0, 2, 1])[:,::-1,...]\n    return dst_L, dst_H","metadata":{"execution":{"iopub.status.busy":"2024-01-10T09:27:21.729238Z","iopub.execute_input":"2024-01-10T09:27:21.729572Z","iopub.status.idle":"2024-01-10T09:27:21.741629Z","shell.execute_reply.started":"2024-01-10T09:27:21.729543Z","shell.execute_reply":"2024-01-10T09:27:21.740675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Wavelet(batch_image):\n    # make channel first image\n    batch_image = K.permute_dimensions(batch_image, [0, 3, 1, 2])\n    r = batch_image[:,0]\n    g = batch_image[:,1]\n    b = batch_image[:,2]\n\n    # level 1 decomposition\n    wavelet_L, wavelet_H = WaveletTransformAxisY(r)\n    r_wavelet_LL, r_wavelet_LH = WaveletTransformAxisX(wavelet_L)\n    r_wavelet_HL, r_wavelet_HH = WaveletTransformAxisX(wavelet_H)\n\n    wavelet_L, wavelet_H = WaveletTransformAxisY(g)\n    g_wavelet_LL, g_wavelet_LH = WaveletTransformAxisX(wavelet_L)\n    g_wavelet_HL, g_wavelet_HH = WaveletTransformAxisX(wavelet_H)\n\n    wavelet_L, wavelet_H = WaveletTransformAxisY(b)\n    b_wavelet_LL, b_wavelet_LH = WaveletTransformAxisX(wavelet_L)\n    b_wavelet_HL, b_wavelet_HH = WaveletTransformAxisX(wavelet_H)\n\n    wavelet_data = [r_wavelet_LL, r_wavelet_LH, r_wavelet_HL, r_wavelet_HH, \n                    g_wavelet_LL, g_wavelet_LH, g_wavelet_HL, g_wavelet_HH,\n                    b_wavelet_LL, b_wavelet_LH, b_wavelet_HL, b_wavelet_HH]\n    transform_batch = K.stack(wavelet_data, axis=1)\n\n    # level 2 decomposition\n    wavelet_L2, wavelet_H2 = WaveletTransformAxisY(r_wavelet_LL)\n    r_wavelet_LL2, r_wavelet_LH2 = WaveletTransformAxisX(wavelet_L2)\n    r_wavelet_HL2, r_wavelet_HH2 = WaveletTransformAxisX(wavelet_H2)\n\n    wavelet_L2, wavelet_H2 = WaveletTransformAxisY(g_wavelet_LL)\n    g_wavelet_LL2, g_wavelet_LH2 = WaveletTransformAxisX(wavelet_L2)\n    g_wavelet_HL2, g_wavelet_HH2 = WaveletTransformAxisX(wavelet_H2)\n\n    wavelet_L2, wavelet_H2 = WaveletTransformAxisY(b_wavelet_LL)\n    b_wavelet_LL2, b_wavelet_LH2 = WaveletTransformAxisX(wavelet_L2)\n    b_wavelet_HL2, b_wavelet_HH2 = WaveletTransformAxisX(wavelet_H2)\n\n\n    wavelet_data_l2 = [r_wavelet_LL2, r_wavelet_LH2, r_wavelet_HL2, r_wavelet_HH2, \n                    g_wavelet_LL2, g_wavelet_LH2, g_wavelet_HL2, g_wavelet_HH2,\n                    b_wavelet_LL2, b_wavelet_LH2, b_wavelet_HL2, b_wavelet_HH2]\n    transform_batch_l2 = K.stack(wavelet_data_l2, axis=1)\n\n    # level 3 decomposition\n    wavelet_L3, wavelet_H3 = WaveletTransformAxisY(r_wavelet_LL2)\n    r_wavelet_LL3, r_wavelet_LH3 = WaveletTransformAxisX(wavelet_L3)\n    r_wavelet_HL3, r_wavelet_HH3 = WaveletTransformAxisX(wavelet_H3)\n\n    wavelet_L3, wavelet_H3 = WaveletTransformAxisY(g_wavelet_LL2)\n    g_wavelet_LL3, g_wavelet_LH3 = WaveletTransformAxisX(wavelet_L3)\n    g_wavelet_HL3, g_wavelet_HH3 = WaveletTransformAxisX(wavelet_H3)\n\n    wavelet_L3, wavelet_H3 = WaveletTransformAxisY(b_wavelet_LL2)\n    b_wavelet_LL3, b_wavelet_LH3 = WaveletTransformAxisX(wavelet_L3)\n    b_wavelet_HL3, b_wavelet_HH3 = WaveletTransformAxisX(wavelet_H3)\n\n    wavelet_data_l3 = [r_wavelet_LL3, r_wavelet_LH3, r_wavelet_HL3, r_wavelet_HH3, \n                    g_wavelet_LL3, g_wavelet_LH3, g_wavelet_HL3, g_wavelet_HH3,\n                    b_wavelet_LL3, b_wavelet_LH3, b_wavelet_HL3, b_wavelet_HH3]\n    transform_batch_l3 = K.stack(wavelet_data_l3, axis=1)\n\n    # level 4 decomposition\n    wavelet_L4, wavelet_H4 = WaveletTransformAxisY(r_wavelet_LL3)\n    r_wavelet_LL4, r_wavelet_LH4 = WaveletTransformAxisX(wavelet_L4)\n    r_wavelet_HL4, r_wavelet_HH4 = WaveletTransformAxisX(wavelet_H4)\n\n    wavelet_L4, wavelet_H4 = WaveletTransformAxisY(g_wavelet_LL3)\n    g_wavelet_LL4, g_wavelet_LH4 = WaveletTransformAxisX(wavelet_L4)\n    g_wavelet_HL4, g_wavelet_HH4 = WaveletTransformAxisX(wavelet_H4)\n\n    wavelet_L3, wavelet_H3 = WaveletTransformAxisY(b_wavelet_LL3)\n    b_wavelet_LL4, b_wavelet_LH4 = WaveletTransformAxisX(wavelet_L4)\n    b_wavelet_HL4, b_wavelet_HH4 = WaveletTransformAxisX(wavelet_H4)\n\n\n    wavelet_data_l4 = [r_wavelet_LL4, r_wavelet_LH4, r_wavelet_HL4, r_wavelet_HH4, \n                    g_wavelet_LL4, g_wavelet_LH4, g_wavelet_HL4, g_wavelet_HH4,\n                    b_wavelet_LL4, b_wavelet_LH4, b_wavelet_HL4, b_wavelet_HH4]\n    transform_batch_l4 = K.stack(wavelet_data_l4, axis=1)\n\n    # print('shape before')\n    # print(transform_batch.shape)\n    # print(transform_batch_l2.shape)\n    # print(transform_batch_l3.shape)\n    # print(transform_batch_l4.shape)\n\n    decom_level_1 = K.permute_dimensions(transform_batch, [0, 2, 3, 1])\n    decom_level_2 = K.permute_dimensions(transform_batch_l2, [0, 2, 3, 1])\n    decom_level_3 = K.permute_dimensions(transform_batch_l3, [0, 2, 3, 1])\n    decom_level_4 = K.permute_dimensions(transform_batch_l4, [0, 2, 3, 1])\n    \n    # print('shape after')\n    # print(decom_level_1.shape)\n    # print(decom_level_2.shape)\n    # print(decom_level_3.shape)\n    # print(decom_level_4.shape)\n    return [decom_level_1, decom_level_2,decom_level_3,decom_level_4]\n\n\ndef Wavelet_out_shape(input_shapes):\n    # print('in to shape')\n    return [tuple([None, 112, 112, 12]), tuple([None, 56, 56, 12]), \n            tuple([None, 28, 28, 12]), tuple([None, 14, 14, 12])]","metadata":{"execution":{"iopub.status.busy":"2024-01-10T09:27:21.743153Z","iopub.execute_input":"2024-01-10T09:27:21.743499Z","iopub.status.idle":"2024-01-10T09:27:21.765369Z","shell.execute_reply.started":"2024-01-10T09:27:21.743449Z","shell.execute_reply":"2024-01-10T09:27:21.764175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, AveragePooling2D, Flatten, Dense\nfrom tensorflow.keras.models import Model\n\n# Fonction pour créer un bloc résiduel\ndef residual_block(x, filters, strides=(1, 1)):\n    # Couches de convolution du bloc résiduel\n    shortcut = x\n    x = Conv2D(filters, kernel_size=(3, 3), strides=strides, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n    x = BatchNormalization()(x)\n    # Connexion résiduelle\n    if strides != (1, 1) or shortcut.shape[-1] != filters:\n        shortcut = Conv2D(filters, kernel_size=(1, 1), strides=strides, padding='same')(shortcut)\n    x = Add()([x, shortcut])\n    x = Activation('relu')(x)\n    return x\nclass SpatialAttention(tf.keras.layers.Layer):\n      def __init__(self, kernel_size):\n        super(SpatialAttention, self).__init__()\n        self.kernel_size = kernel_size\n        \n        def build(self, input_shape):\n            self.conv2d = tf.keras.layers.Conv2D(filters = 1,\n                    kernel_size=self.kernel_size,\n                    strides=1,\n                    padding='same',\n                    activation='sigmoid',\n                    kernel_initializer='he_normal',\n                    use_bias=False)\n\n        def call(self, inputs):\n            \n            # AvgPool\n            avg_pool = tf.keras.layers.Lambda(lambda x: tf.keras.backend.mean(x, axis=3, keepdims=True))(inputs)\n            \n            # MaxPool\n            max_pool = tf.keras.layers.Lambda(lambda x: tf.keras.backend.max(x, axis=3, keepdims=True))(inputs)\n\n            attention = tf.keras.layers.Concatenate(axis=3)([avg_pool, max_pool])\n\n            attention = self.conv2d(attention)\n\n\n            return tf.keras.layers.multiply([inputs, attention]) \nclass ChannelAttention(tf.keras.layers.Layer):\n      def __init__(self, filters, ratio):\n        super(ChannelAttention, self).__init__()\n        self.filters = filters\n        self.ratio = ratio\n\n        def build(self, input_shape):\n            self.shared_layer_one = tf.keras.layers.Dense(self.filters//self.ratio,\n                             activation='relu', kernel_initializer='he_normal', \n                              use_bias=True, \n                              bias_initializer='zeros')\n            self.shared_layer_two = tf.keras.layers.Dense(self.filters,\n                             kernel_initializer='he_normal',\n                             use_bias=True,\n                             bias_initializer='zeros')\n\n        def call(self, inputs):\n            # AvgPool\n            avg_pool = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n            \n\n            avg_pool = self.shared_layer_one(avg_pool)\n            avg_pool = self.shared_layer_two(avg_pool)\n\n            # MaxPool\n            max_pool = tf.keras.layers.GlobalMaxPooling2D()(inputs)\n            max_pool = tf.keras.layers.Reshape((1,1,filters))(max_pool)\n\n            max_pool = shared_layer_one(max_pool)\n            max_pool = shared_layer_two(max_pool)\n\n\n            attention = tf.keras.layers.Add()([avg_pool,max_pool])\n            attention = tf.keras.layers.Activation('sigmoid')(attention)\n            \n            return tf.keras.layers.Multiply()([inputs, attention])\ndef get_wavelet_cnn_model():\n    input_shape = 224, 224, 3\n\n    input_ = Input(input_shape, name='the_input')\n    wavelet = Lambda(Wavelet, Wavelet_out_shape, name='wavelet')\n    input_l1, input_l2, input_l3, input_l4 = wavelet(input_)\n\n    # Adjust the number of channels in wavelet decomposition output\n    input_l1 = Conv2D(64, kernel_size=(1, 1), padding='same', name='adjust_channels_l1')(input_l1)\n    input_l2 = Conv2D(64, kernel_size=(1, 1), padding='same', name='adjust_channels_l2')(input_l2)\n    input_l3 = Conv2D(64, kernel_size=(1, 1), padding='same', name='adjust_channels_l3')(input_l3)\n    input_l4 = Conv2D(64, kernel_size=(1, 1), padding='same', name='adjust_channels_l4')(input_l4)\n\n    # Architecture ResNet avec les blocs résiduels et les blocs de transformation en ondelettes\n\n    x = input_\n    x = Conv2D(64, kernel_size=(7, 7), strides=(2, 2), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n\n\n\n    # Niveau 1\n    x = input_l1\n    relu_a = residual_block(x, filters=64, strides=(2, 2))\n    #relu_a=ChannelAttention(128, 8)(relu_a)\n    relu_a=SpatialAttention(10)(relu_a)\n\n    # Niveau 2\n    x = input_l2\n    for _ in range(2):\n        relu_1_2 = residual_block(x, filters=64)\n    #relu_1_2=ChannelAttention(128, 8)(relu_1_2)\n    relu_1_2=SpatialAttention(10)(relu_1_2)\n      \n    print(\"conc\")\n    concate_level_2 = concatenate([relu_1_2, relu_a])\n    relu_2_2 = residual_block(concate_level_2, filters=128, strides=(2, 2))\n    print(relu_2_2)\n        \n        \n    x = input_l3\n    relu_b_2 = residual_block(x, filters=64)\n    for _ in range(2):\n        relu_b_2 = residual_block(relu_b_2, filters=128)\n    #relu_b_2=ChannelAttention(128, 8)(relu_b_2)\n    relu_b_2=SpatialAttention(10)(relu_b_2)\n\n    concate_level_3 = concatenate([relu_2_2, relu_b_2])\n    print(\"conc\")\n    print(concate_level_3)\n    relu_3_2 = residual_block(concate_level_3, filters=256, strides=(2, 2))\n    \n    # Niveau 3\n    x = input_l4\n    relu_c_3 = residual_block(x, filters=64)\n    for _ in range(2):\n        relu_c_3 = residual_block(relu_c_3, filters=256)\n    #relu_c_3=ChannelAttention(128, 8)(relu_c_3)\n    relu_c_3=SpatialAttention(10)(relu_c_3)\n    concate_level_4 = concatenate([relu_3_2, relu_c_3])\n    print(\"conc\")\n    print(concate_level_4)\n    conv_4 = Conv2D(256, kernel_size=(3, 3), padding='same', name='conv_4')(concate_level_4)\n    norm_4 = BatchNormalization(name='norm_4')(conv_4)\n    relu_4 = Activation('relu', name='relu_4')(norm_4)\n\n    conv_4_2 = Conv2D(256, kernel_size=(3, 3), strides=(2, 2), padding='same', name='conv_4_2')(relu_4)\n    norm_4_2 = BatchNormalization(name='norm_4_2')(conv_4_2)\n    relu_4_2 = Activation('relu', name='relu_4_2')(norm_4_2)\n\n    conv_5_1 = Conv2D(128, kernel_size=(3, 3), padding='same', name='conv_5_1')(relu_4_2)\n    norm_5_1 = BatchNormalization(name='norm_5_1')(conv_5_1)\n    relu_5_1 = Activation('relu', name='relu_5_1')(norm_5_1)\n\n    pool_5_1 = AveragePooling2D(pool_size=(7, 7), strides=1, padding='same', name='avg_pool_5_1')(relu_5_1)\n    flat_5_1 = Flatten(name='flat_5_1')(pool_5_1) \n    \n    fc_5 = Dense(2048, name='fc_5')(flat_5_1)\n    norm_5 = BatchNormalization(name='norm_5')(fc_5)\n    relu_5 = Activation('relu', name='relu_5')(norm_5)\n    drop_5 = Dropout(0.5, name='drop_5')(relu_5)\n\n    fc_6 = Dense(2048, name='fc_6')(drop_5)\n    norm_6 = BatchNormalization(name='norm_6')(fc_6)\n    relu_6 = Activation('relu', name='relu_6')(norm_6)\n    drop_6 = Dropout(0.5, name='drop_6')(relu_6)\n\n    output = Dense(7, activation='softmax', name='fc_7')(drop_6)\n    \n    model = Model(inputs=input_, outputs=output)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-01-10T09:27:21.767243Z","iopub.execute_input":"2024-01-10T09:27:21.767660Z","iopub.status.idle":"2024-01-10T09:27:21.805986Z","shell.execute_reply.started":"2024-01-10T09:27:21.767623Z","shell.execute_reply":"2024-01-10T09:27:21.804811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#wavelet model\nwavelet = get_wavelet_cnn_model()","metadata":{"execution":{"iopub.status.busy":"2024-01-10T09:27:21.808374Z","iopub.execute_input":"2024-01-10T09:27:21.808803Z","iopub.status.idle":"2024-01-10T09:27:23.769658Z","shell.execute_reply.started":"2024-01-10T09:27:21.808767Z","shell.execute_reply":"2024-01-10T09:27:23.768603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf \ndisplay(tf.keras.utils.plot_model(wavelet, \n                                  show_shapes=True, \n                                  show_layer_names=True,\n                                  expand_nested=True))","metadata":{"execution":{"iopub.status.busy":"2024-01-10T09:27:23.774325Z","iopub.execute_input":"2024-01-10T09:27:23.774773Z","iopub.status.idle":"2024-01-10T09:27:25.634254Z","shell.execute_reply.started":"2024-01-10T09:27:23.774734Z","shell.execute_reply":"2024-01-10T09:27:25.633170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf \nfrom tensorflow import keras \nfrom tensorflow.keras import layers\n\n# Multi-Atrous Branch\nclass MultiAtrous(keras.Model):\n    def __init__(self, \n                 dilation_rates=[6, 12, 18], \n                 upsampling=1, \n                 kernel_size=3, \n                 padding=\"same\",  **kwargs):\n        super(MultiAtrous, self).__init__(name='MultiAtrous', **kwargs)\n        self.dilation_rates = dilation_rates\n        self.kernel_size = kernel_size \n        self.upsampling = upsampling\n        self.padding = padding\n      \n        # Dilated Convolutions                     \n        self.dilated_convs = [\n                              layers.Conv2D(\n                                  filters       = int(1024 / 4), \n                                  kernel_size   = self.kernel_size,  \n                                  padding       = self.padding, \n                                  dilation_rate = rate\n                                ) for rate in self.dilation_rates\n                             ]\n        \n        # Global Average Pooling Branch \n        self.gap_branch = keras.Sequential(\n            [\n                layers.GlobalAveragePooling2D(keepdims=True),\n                layers.Conv2D(int(1024 / 2), kernel_size=1),\n                layers.Activation('relu'),\n                layers.UpSampling2D(size=self.upsampling, interpolation=\"bilinear\")\n            ] , name='gap_branch'\n        )\n        \n    def call(self, inputs, training=None, **kwargs):\n        local_feature = []\n        for dilated_conv in self.dilated_convs:\n            x = dilated_conv(inputs) \n            x = self.gap_branch(x)\n            local_feature.append(x)\n        return tf.concat(local_feature, axis=-1)\n\n    def get_config(self):\n        config = {\n            'dilation_rates': self.dilation_rates,\n            'kernel_size'   : self.kernel_size,\n            'padding'       : self.padding,\n            'upsampling'    : self.upsampling\n        }\n        base_config = super(MultiAtrous, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n","metadata":{"execution":{"iopub.status.busy":"2024-01-10T09:27:25.635672Z","iopub.execute_input":"2024-01-10T09:27:25.636051Z","iopub.status.idle":"2024-01-10T09:27:25.652625Z","shell.execute_reply.started":"2024-01-10T09:27:25.636017Z","shell.execute_reply":"2024-01-10T09:27:25.651305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GeneralizedMeanPooling2D(layers.Layer):\n    def __init__(self, init_norm=3.0, normalize=False, epsilon=1e-6, **kwargs):\n        self.init_norm = init_norm\n        self.normalize = normalize\n        self.epsilon   = epsilon\n        super(GeneralizedMeanPooling2D, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.p = self.add_weight(name=\"norms\", \n                                 shape=(input_shape[-1],),\n                                 initializer=keras.initializers.constant(self.init_norm),\n                                 trainable=True)\n        super(GeneralizedMeanPooling2D, self).build(input_shape)\n\n    def call(self, inputs):\n        x = tf.abs(tf.maximum(self.epsilon, inputs))\n        x = tf.pow(x, self.p)\n        x = tf.reduce_mean(x, axis=[1,2], keepdims=False) \n        x = tf.pow(x, (1.0 / self.p))\n        if self.normalize:\n            x = tf.nn.l2_normalize(x, 1)\n        return x\n\n    def get_config(self):\n        config = {\n            'init_norm' : self.init_norm,\n            'normalize' : self.normalize,\n            'epsilon'   : self.epsilon\n        }\n        base_config = super(GeneralizedMeanPooling2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n","metadata":{"execution":{"iopub.status.busy":"2024-01-10T09:27:25.653932Z","iopub.execute_input":"2024-01-10T09:27:25.654270Z","iopub.status.idle":"2024-01-10T09:27:25.669183Z","shell.execute_reply.started":"2024-01-10T09:27:25.654233Z","shell.execute_reply":"2024-01-10T09:27:25.668016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SkinNet(keras.Model):\n    def __init__(self, backbone=None, num_classes=1, activation=None, **kwargs):\n        super(SkinNet, self).__init__(name='SkinNet', **kwargs)\n        # Number of classes \n        self.num_classes = num_classes\n        self.activation  = activation\n        \n        # Base blcoks \n        self.base = backbone\n        self.base_input_shape  = self.base.input_shape[0][1]\n\n        self.glob_branch_pool = keras.Sequential(\n            [\n                GeneralizedMeanPooling2D(),\n                layers.Dense(1024, activation=None)\n            ], \n            name='GlobalBranchPooling'\n        )\n        \n        # Head block\n        self.classifier = keras.Sequential(\n            [\n                #layers.GlobalAveragePooling2D(name='HeadGAP'),\n                layers.Dense(self.num_classes, activation = self.activation)\n            ], \n            name='Classifiers'\n        )\n       \n    # forwarding the computation \n    def call(self, inputs, training=None, **kwargs):\n        # Get tensor from target layers \n        to_global= self.base(inputs)\n\n        # Pass the received tensor to Top building blocks \n        global_feat    = self.glob_branch_pool(to_global)\n        return self.classifier(global_feat)\n    \"\"\"\n    def train_step(self, data):\n        return train_step_sam(self, data, rho=0.05)\n    \"\"\"\n\n    def build_graph(self):\n        x = keras.Input(shape=(self.base_input_shape, self.base_input_shape, 3))\n        return keras.Model(inputs=[x], outputs=self.call(x))","metadata":{"execution":{"iopub.status.busy":"2024-01-10T09:27:25.670783Z","iopub.execute_input":"2024-01-10T09:27:25.671513Z","iopub.status.idle":"2024-01-10T09:27:25.687860Z","shell.execute_reply.started":"2024-01-10T09:27:25.671453Z","shell.execute_reply":"2024-01-10T09:27:25.686617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import applications, layers, Model, Input\n\nfor l in wavelet.layers:\n    print(l.name, l.output_shape)  ","metadata":{"execution":{"iopub.status.busy":"2024-01-10T09:27:25.689263Z","iopub.execute_input":"2024-01-10T09:27:25.689679Z","iopub.status.idle":"2024-01-10T09:27:25.708168Z","shell.execute_reply.started":"2024-01-10T09:27:25.689644Z","shell.execute_reply":"2024-01-10T09:27:25.707121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#9bel mnni kente dayra wavelet 3adi bla residual block kent dayra ghir model.input ms 3tatni error 'nonetype' dkchi 3lash\n#beddeltha b hadi model.inputs\nnew_base = keras.Model(\n    [wavelet.inputs], \n    [\n        wavelet.get_layer('relu_4').output # for global branch (None, 14, 14, 256)\n    ], \n    name='Wavelet'\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T09:27:25.709365Z","iopub.execute_input":"2024-01-10T09:27:25.710420Z","iopub.status.idle":"2024-01-10T09:27:25.729851Z","shell.execute_reply.started":"2024-01-10T09:27:25.710377Z","shell.execute_reply":"2024-01-10T09:27:25.728665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skin_net = SkinNet(new_base, num_classes=7, activation='softmax')\nskin_net.build_graph().summary()","metadata":{"execution":{"iopub.status.busy":"2024-01-10T09:27:25.731143Z","iopub.execute_input":"2024-01-10T09:27:25.731445Z","iopub.status.idle":"2024-01-10T09:27:26.785653Z","shell.execute_reply.started":"2024-01-10T09:27:25.731417Z","shell.execute_reply":"2024-01-10T09:27:26.784545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.config.optimizer.set_jit(True)\ndef compileNewModel():\n    \n    ''' Configuring the model with losses and metrics. '''    \n    \n    with strategy.scope():\n        model = skin_net\n\n    with strategy.scope():\n        model.compile(optimizer='adam', loss='categorical_crossentropy', \n                      metrics=['accuracy'])\n        #tf.keras.metrics.AUC(name='auc')\n    return model\n\ndef getLearnRateCallback(cfg):\n    \n    ''' Using callbacks for learning rate adjustments. '''\n    \n    lr_start = cfg['lr_start']\n    lr_max = cfg['lr_max'] * strategy.num_replicas_in_sync * cfg['batch_size']\n    lr_min = cfg['lr_min']\n    lr_rampup = cfg['lr_rampup']\n    lr_sustain = cfg['lr_sustain']\n    lr_decay = cfg['lr_decay']\n\n    def lrfn(epoch):\n        if epoch < lr_rampup:\n            lr = (lr_max - lr_start) / lr_rampup * epoch + lr_start\n        elif epoch < lr_rampup + lr_sustain:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_rampup -\n                                                lr_sustain) + lr_min\n        return lr\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n    return lr_callback\n\n\ndef learnModel(model, ds_train, cfg, ds_val):\n    \n    ''' Fitting things together for training '''\n    \n    filepath1 = \"Skin_attent_weights_acc_att_wave_14.h5\"\n    checkpoint = ModelCheckpoint(filepath1, monitor='val_accuracy', verbose=1, \n                             save_best_only=True, mode='max', save_weights_only = True)\n    callbacks = [getLearnRateCallback(cfg), checkpoint]\n\n    history = model.fit(ds_train,\n                        validation_data=ds_val,\n                        verbose=True,\n                        epochs=200,\n                        callbacks=callbacks)\n\n    return history","metadata":{"execution":{"iopub.status.busy":"2024-01-10T09:27:26.787147Z","iopub.execute_input":"2024-01-10T09:27:26.787525Z","iopub.status.idle":"2024-01-10T09:27:26.799963Z","shell.execute_reply.started":"2024-01-10T09:27:26.787462Z","shell.execute_reply":"2024-01-10T09:27:26.798873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = compileNewModel()\nhistory = learnModel(model, train_batches, cfg, valid_batches)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T09:27:26.801054Z","iopub.execute_input":"2024-01-10T09:27:26.801360Z","iopub.status.idle":"2024-01-10T09:28:53.433147Z","shell.execute_reply.started":"2024-01-10T09:27:26.801333Z","shell.execute_reply":"2024-01-10T09:28:53.431619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('Skin_attent_weights_acc_att_wave_14.h5')","metadata":{"execution":{"iopub.status.busy":"2024-01-10T09:28:53.433992Z","iopub.status.idle":"2024-01-10T09:28:53.434356Z","shell.execute_reply.started":"2024-01-10T09:28:53.434181Z","shell.execute_reply":"2024-01-10T09:28:53.434198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_weights('Skin_attent_weights_acc_att_wave_14.h5')","metadata":{"execution":{"iopub.status.busy":"2024-01-10T09:28:53.435710Z","iopub.status.idle":"2024-01-10T09:28:53.436084Z","shell.execute_reply.started":"2024-01-10T09:28:53.435906Z","shell.execute_reply":"2024-01-10T09:28:53.435924Z"},"trusted":true},"execution_count":null,"outputs":[]}]}